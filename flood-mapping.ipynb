{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2baee765",
   "metadata": {},
   "source": [
    "# Earth Observation Data Scientist \n",
    "We are asked to build a Python Notebook and a slide deck to assess the impact\n",
    "of floodings during the Gloria storm (Januray 15th-25th, 2020) in an area of\n",
    "interest of our choosing inside the Maresme county along the Tordera river\n",
    "(Catalonia, Spain) with at least one of the following analytics:\n",
    "1. Number of square kilometers affected by the floodings.\n",
    "2. The affected population.\n",
    "3. The affected roads.\n",
    "\n",
    "The chosen AoI if the Tordera municipality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69e020",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b6409d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing jpy: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m                              \u001b[38;5;66;03m# data analysis and manipulation\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnappy\u001b[39;00m                                 \u001b[38;5;66;03m# SNAP Python interface\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjpy\u001b[39;00m                                    \u001b[38;5;66;03m# Python-Java bridge\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m                        \u001b[38;5;66;03m# threshold calculation\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m                              \u001b[38;5;66;03m# higher-order functions and operations\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing jpy: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# MODULE                                      # DESCRIPTION\n",
    "import sys\n",
    "import matplotlib.pyplot as plt               # create visualizations\n",
    "import numpy as np                            # scientific comupting\n",
    "import json                                   # JSON encoder and decoder\n",
    "import glob                                   # data access\n",
    "import os                                     # data access\n",
    "import ipywidgets                             # interactive UI controls\n",
    "import time                                   # time assessment\n",
    "import shutil                                 # file operations\n",
    "import ipyleaflet                             # visualization\n",
    "import geopandas                              # data analysis and manipulation\n",
    "import snappy                                 # SNAP Python interface\n",
    "import jpy                                    # Python-Java bridge\n",
    "import skimage.filters                        # threshold calculation\n",
    "import functools                              # higher-order functions and operations\n",
    "from ipyfilechooser import FileChooser        # file chooser widget\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt  # interface to Open Access Hub\n",
    "from datetime import date                     # dates, times and intervalls\n",
    "from IPython.display import display           # visualization\n",
    "from osgeo import ogr, gdal, osr              # data conversion\n",
    "from zipfile import ZipFile                   # file management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15715182",
   "metadata": {},
   "source": [
    "# Processing\n",
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c797154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create S1 product\n",
    "def get_scene(sar_data, geojson):\n",
    "    # set correct path of input file and create S1 product\n",
    "    S1_source = snappy.ProductIO.readProduct(sar_data)\n",
    "\n",
    "    # read geographic coordinates from Sentinel-1 image meta data\n",
    "    meta_data = S1_source.getMetadataRoot().getElement('Abstracted_Metadata')\n",
    "    # refines center of map according to Sentinel-1 image\n",
    "    center = (meta_data.getAttributeDouble('centre_lat'), meta_data.getAttributeDouble('centre_lon'))\n",
    "    locations = [[{'lat' : meta_data.getAttributeDouble('first_near_lat'), 'lng' : meta_data.getAttributeDouble('first_near_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('last_near_lat'),  'lng' : meta_data.getAttributeDouble('last_near_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('last_far_lat'),   'lng' : meta_data.getAttributeDouble('last_far_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('first_far_lat'),  'lng' : meta_data.getAttributeDouble('first_far_long')}]]\n",
    "\n",
    "    # creates interactive map\n",
    "    basic_map = ipyleaflet.Map(center = center, zoom = 7.5)\n",
    "    # defines fixed polygon illustrating Sentinel-1 image\n",
    "    polygon_fix = ipyleaflet.Polygon(locations = locations, color='royalblue')\n",
    "    basic_map.add_layer(polygon_fix)\n",
    "    # displays map\n",
    "    basic_map.add_control(ipyleaflet.ScaleControl(position='bottomleft'))\n",
    "    display(basic_map)\n",
    "    \n",
    "    # check whether AOI file is given and convert to JSON in order to show AOI on map\n",
    "    try:\n",
    "        # calls readJSONfromAOI function to get GeoJSON from either JSON, SHP, or KMZ file\n",
    "        data_json = readJSONFromAOI('%s/AOI' % directory)\n",
    "        # show AOI on map according to JSON data\n",
    "        basic_map.add_layer(ipyleaflet.GeoJSON(data = data_json, style = {'color' : 'green'}))\n",
    "        # apply subset according to JSON data\n",
    "        footprint = geojson_to_wkt(data_json)\n",
    "        # run processing process\n",
    "        processing(S1_source, footprint)\n",
    "        \n",
    "    # if no AOI is given, it needs to be selected manually\n",
    "    except:\n",
    "        # editable polygon determining AOI\n",
    "        polygon_flex = ipyleaflet.Polygon(locations = locations,\n",
    "                                          color = 'green',\n",
    "                                          fill_color = 'green',\n",
    "                                          transform = True)\n",
    "        basic_map.add_layer(polygon_flex)\n",
    "        # create process button and call function to start ptocessing when clicked\n",
    "        processButton = ipywidgets.Button(description = 'Start Processing')\n",
    "        processButton.on_click(functools.partial(on_processButton_clicked,\n",
    "                                                 S1_source = S1_source,\n",
    "                                                 polygon_flex = polygon_flex))\n",
    "        display(processButton)\n",
    "    \n",
    "# calculate and return threshold of 'Band'-type input\n",
    "def get_threshold(S1_band):\n",
    "    # read band\n",
    "    w = S1_band.getRasterWidth()\n",
    "    h = S1_band.getRasterHeight()\n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    S1_band.readPixels(0, 0, w, h, band_data)\n",
    "    band_data.shape = h * w\n",
    "\n",
    "    # calculate threshold using Otsu method\n",
    "    threshold_otsu = skimage.filters.threshold_otsu(band_data)\n",
    "    # calculate threshold using minimum method\n",
    "    threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "    # get number of pixels for both thresholds\n",
    "    numPixOtsu = len(band_data[abs(band_data - threshold_otsu) < 0.1])\n",
    "    numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "    # if number of pixels at minimum threshold is less than 1% of number of pixels at Otsu threshold\n",
    "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
    "        # adjust band data according\n",
    "        if threshold_otsu < threshold_minimum:\n",
    "            band_data = band_data[band_data < threshold_minimum]\n",
    "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "        else:\n",
    "            band_data = band_data[band_data > threshold_minimum]\n",
    "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "    \n",
    "        numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "    # select final threshold\n",
    "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
    "        threshold = threshold_otsu\n",
    "    else:\n",
    "        threshold = threshold_minimum\n",
    "\n",
    "    return threshold\n",
    "\n",
    "# calculate binary mask of 'Product'-type intput with respect expression in string array\n",
    "def binarization(S1_product, expressions):\n",
    "\n",
    "    BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "    targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(expressions))\n",
    "\n",
    "    # loop through bands\n",
    "    for i in range(len(expressions)):\n",
    "        targetBand = BandDescriptor()\n",
    "        targetBand.name = '%s' % S1_product.getBandNames()[i]\n",
    "        targetBand.type = 'float32'\n",
    "        targetBand.expression = expressions[i]\n",
    "        targetBands[i] = targetBand\n",
    "    \n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('targetBands', targetBands)    \n",
    "    mask = snappy.GPF.createProduct('BandMaths', parameters, S1_product)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# processing steps\n",
    "def processing(S1_source, footprint):\n",
    "    \n",
    "    # Subset operator\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('copyMetadata', True)\n",
    "    geom = snappy.WKTReader().read(footprint)\n",
    "    parameters.put('geoRegion', geom)\n",
    "    parameters.put('sourceBands', sourceBands)\n",
    "    S1_crop = snappy.GPF.createProduct('Subset', parameters, S1_source)\n",
    "    # status update\n",
    "    print('\\nSubset successfully generated.\\n', flush=True)\n",
    "    \n",
    "    # Apply-Orbit-File operator\n",
    "    print('1. Apply Orbit File:          ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    # continue with calculation in case no orbit file is available yet\n",
    "    parameters.put('continueOnFail', True)\n",
    "    S1_Orb = snappy.GPF.createProduct('Apply-Orbit-File', parameters, S1_crop)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # ThermalNoiseRemoval operator\n",
    "    print('2. Thermal Noise Removal:     ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('removeThermalNoise', True)\n",
    "    S1_Thm = snappy.GPF.createProduct('ThermalNoiseRemoval', parameters, S1_Orb)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Calibration operator\n",
    "    print('3. Radiometric Calibration:   ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('outputSigmaBand', True)\n",
    "    S1_Cal = snappy.GPF.createProduct('Calibration', parameters, S1_Thm)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Speckle-Filter operator\n",
    "    print('4. Speckle Filtering:         ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('filter', 'Lee')\n",
    "    parameters.put('filterSizeX', 5)\n",
    "    parameters.put('filterSizeY', 5)\n",
    "    S1_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_Cal)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Conversion from linear to db operator\n",
    "    S1_Spk_db = snappy.GPF.createProduct('LinearToFromdB', snappy.HashMap(), S1_Spk)\n",
    "\n",
    "    # Terrain-Correction operator\n",
    "    print('5. Terrain Correction:        ', end='', flush=True)\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('demName', 'SRTM 1Sec HGT')\n",
    "    parameters.put('demResamplingMethod', 'BILINEAR_INTERPOLATION')\n",
    "    parameters.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
    "    parameters.put('pixelSpacingInMeter', 10.0)\n",
    "    parameters.put('nodataValueAtSea', False)\n",
    "    parameters.put('saveSelectedSourceBand', True)\n",
    "    S1_TC = snappy.GPF.createProduct('Terrain-Correction', parameters, S1_Spk_db)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Binarization\n",
    "    print('6. Binarization:              ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    # add GlobCover band\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('landCoverNames', 'GlobCover')\n",
    "    GlobCover = snappy.GPF.createProduct('AddLandCover', parameters, S1_TC)\n",
    "    # empty string array for binarization band maths expression(s)\n",
    "    expressions = ['' for i in range(S1_TC.getNumBands())]\n",
    "    # empty array for threshold(s)\n",
    "    thresholds = np.zeros(S1_TC.getNumBands())\n",
    "    # loop through bands\n",
    "    for i in range(S1_TC.getNumBands()):\n",
    "        # calculate threshold of band and store in float array\n",
    "        # use S1_Spk_db product for performance reasons. S1_TC causes 0-values\n",
    "        # which distort histogram and thus threshold result\n",
    "        thresholds[i] = getThreshold(S1_Spk_db.getBandAt(i))\n",
    "        # formulate expression according to threshold and store in string array\n",
    "        expressions[i] = 'if (%s < %s && land_cover_GlobCover != 210) then 1 else NaN' % (S1_TC.getBandNames()[i], thresholds[i])\n",
    "    # do binarization\n",
    "    S1_floodMask = binarization(GlobCover, expressions)\n",
    "    print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Speckle-Filter operator\n",
    "    print('7. Speckle Filtering:         ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('filter', 'Median')\n",
    "    parameters.put('filterSizeX', 5)\n",
    "    parameters.put('filterSizeY', 5)\n",
    "    # define flood mask as global for later access\n",
    "    global S1_floodMask_Spk\n",
    "    S1_floodMask_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_floodMask)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # output\n",
    "    if plotResoluts:\n",
    "        print('8. Plot:                      ', end='', flush=True)\n",
    "        start_time = time.time()\n",
    "        for i in range(S1_TC.getNumBands()):\n",
    "            plotBand(S1_TC.getBandAt(i), thresholds[i])\n",
    "        print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b592b",
   "metadata": {},
   "source": [
    "### Scene generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd644c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter required polarisation(s) and set output file name accordingly\n",
    "source_bands = 'Amplitude_VH,Intensity_VH'\n",
    "output_extensions   = 'processed_VH'\n",
    "\n",
    "# path of Sentinel-1 .zip input file\n",
    "input_path = os.path.join(directory, 'data', 'sar', 'data.zip')\n",
    "footprint = os.path.join(directory, 'data', 'aoi', 'aoi.geojson')\n",
    "# apply subset according to JSON data\n",
    "get_scene(input_path, footprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740cbfc",
   "metadata": {},
   "source": [
    "# Data exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb39d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exporting...\\n', flush=True)\n",
    "# check if output folders exists, if not create folders\n",
    "output_path = os.path.join(directory, 'output')\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "GeoTIFF_path = os.path.join(output_path, 'GeoTIFF')\n",
    "if not os.path.isdir(GeoTIFF_path):\n",
    "    os.mkdir(GeoTIFF_path)\n",
    "SHP_path = os.path.join(output_path, 'SHP')\n",
    "if not os.path.isdir(SHP_path):\n",
    "    os.mkdir(SHP_path)\n",
    "KML_path = os.path.join(output_path, 'KML')\n",
    "if not os.path.isdir(KML_path):\n",
    "    os.mkdir(KML_path)\n",
    "GeoJSON_path = os.path.join(output_path, 'GeoJSON')\n",
    "if not os.path.isdir(GeoJSON_path):\n",
    "    os.mkdir(GeoJSON_path)\n",
    "# get file name if file chooser was used\n",
    "if len(files) is not 1: input_name = fc.selected_filename\n",
    "\n",
    "# convert GeoTIFF to SHP\n",
    "print('2. SHP:                       ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "# allow GDAL to throw Python exceptions\n",
    "gdal.UseExceptions()\n",
    "open_image = gdal.Open('%s/%s_%s.tif' % (GeoTIFF_path, os.path.splitext(input_name)[0], output_extensions))\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(open_image.GetProjectionRef())\n",
    "shp_driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "# empty string array for bands in GeoTIFF\n",
    "output_shp = ['' for i in range(open_image.RasterCount)]\n",
    "if open_image.RasterCount == 1:\n",
    "    output_shp[0] = '%s/%s_processed_%s' % (SHP_path, os.path.splitext(input_name)[0], polarisations)\n",
    "else:\n",
    "    VH_SHP_path = os.path.join(SHP_path, 'VH')\n",
    "    if not os.path.isdir(VH_SHP_path):\n",
    "        os.mkdir(VH_SHP_path)\n",
    "    VV_SHP_path = os.path.join(SHP_path, 'VV')\n",
    "    if not os.path.isdir(VV_SHP_path):\n",
    "        os.mkdir(VV_SHP_path)\n",
    "    output_shp[0] = '%s/%s_processed_VH' % (VH_SHP_path, os.path.splitext(input_name)[0])\n",
    "    output_shp[1] = '%s/%s_processed_VV' % (VV_SHP_path, os.path.splitext(input_name)[0])\n",
    "# loops through bands in GeoTIFF\n",
    "for i in range(open_image.RasterCount):\n",
    "    input_band = open_image.GetRasterBand(i+1)\n",
    "    output_shapefile = shp_driver.CreateDataSource(output_shp[i] + '.shp')\n",
    "    new_shapefile = output_shapefile.CreateLayer(output_shp[i], srs=srs)\n",
    "    new_shapefile.CreateField(ogr.FieldDefn('DN', ogr.OFTInteger))\n",
    "    gdal.Polygonize(input_band, input_band.GetMaskBand(), new_shapefile, 0, [], callback=None)\n",
    "    # filters attributes with values other than 1 (sould be NaN or respective value)\n",
    "    new_shapefile.SetAttributeFilter('DN != 1')\n",
    "    for feat in new_shapefile:\n",
    "        new_shapefile.DeleteFeature(feat.GetFID())\n",
    "    new_shapefile.SyncToDisk()\n",
    "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "# convert SHP to GeoJSON\n",
    "print('4. GeoJSON:                   ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "if open_image.RasterCount == 1:\n",
    "    shp_file = geopandas.read_file('%s/%s_processed_%s.shp' % (SHP_path, os.path.splitext(input_name)[0], polarisations))\n",
    "    shp_file.to_file('%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], polarisations), driver='GeoJSON')\n",
    "else:\n",
    "    shp_file_VH = geopandas.read_file('%s/%s_processed_VH.shp' % (VH_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    shp_file_VH.to_file('%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')    \n",
    "    shp_file_VV = geopandas.read_file('%s/%s_processed_VV.shp' % (VV_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    shp_file_VV.to_file('%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')\n",
    "print('--- %.2f seconds ---\\n' % (time.time() - start_time), flush=True)\n",
    "print('Files successfuly stored under %s.\\n' % output_path, flush=True)\n",
    "\n",
    "# plot results\n",
    "results_map = ipyleaflet.Map(zoom=9, basemap=ipyleaflet.basemaps.OpenStreetMap.Mapnik)    \n",
    "if open_image.RasterCount == 1:\n",
    "    file = '%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], polarisations)\n",
    "    with open(file, 'r') as f:\n",
    "        data_json = json.load(f) \n",
    "    mask = ipyleaflet.GeoJSON(data = data_json, name = 'Flood Mask', style = {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask)\n",
    "    results_map.center = (mask.data['features'][0]['geometry']['coordinates'][0][0][1],\n",
    "                          mask.data['features'][0]['geometry']['coordinates'][0][0][0])\n",
    "else:\n",
    "    file_VV = '%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
    "    with open(file_VV, 'r') as f_VV:\n",
    "        data_json_VV = json.load(f_VV)\n",
    "    mask_VV = ipyleaflet.GeoJSON(data = data_json_VV, name = 'Flood Mask: VV', style = {'color':'red', 'opacity':'1', 'fillColor':'red', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask_VV)\n",
    "    results_map.center = (mask_VV.data['features'][0]['geometry']['coordinates'][0][0][1],\n",
    "                          mask_VV.data['features'][0]['geometry']['coordinates'][0][0][0])  \n",
    "    file_VH = '%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
    "    with open(file_VH, 'r') as f_VH:\n",
    "        data_json_VH = json.load(f_VH)\n",
    "    mask_VH = ipyleaflet.GeoJSON(data = data_json_VH, name = 'Flood Mask: VH', style = {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask_VH)\n",
    "results_map.add_control(ipyleaflet.FullScreenControl())\n",
    "results_map.add_control(ipyleaflet.LayersControl(position='topright'))\n",
    "results_map.add_control(ipyleaflet.ScaleControl(position='bottomleft'))\n",
    "display(results_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
